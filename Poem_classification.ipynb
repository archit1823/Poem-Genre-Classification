{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading csv file in pandas dataframe i've extracted content('poems') and type('genre') from it.\n",
    "Poems will be used as input samples and genre will be the output.\n",
    "\n",
    "Then I've shuffled the data and split it into training and testing using train_test_split.\n",
    "Now I've created documents, where each row of the document represents input('poem') and it's corresponding output('genre').\n",
    "clean_documents() function takes each poem and filter out the punctuations, stop_words and convert each word to a lowercase letter after splitting it into tokens. PosTag is used to marking up a particular word corresponding to a particular part of speech based on its context.\n",
    "\n",
    "After training the document, I've joined the filtered tokens back together and CountVectorizer is used to convert a collection of text documents to a matrix of tokens count.\n",
    "I've used RandomForestClassifier, SVC, MultiNomialNB to classify poems and all three have been compared based on accuracy.\n",
    "\n",
    "SVC gives the best accuracy among all three classifiers with training accuracy of about 89%, so I've used GridSearchCV to find the best parameters and testing accuracy increased to about 70%. for SVC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import gzip, json\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the path and Run All cells.\n",
    "path = \"C:\\\\Users\\\\Archit\\\\Desktop\\\\internship\\\\intellify\\\\all.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's a library in nltk that provides pos_tag value (eg. whether a word is used as adjective or a verb etc in a sentence and then \n",
    "# using lemmatizer we can change the word accordingly).\n",
    "from nltk.corpus import wordnet\n",
    "def get_pos_tag_value(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>poem name</th>\n",
       "      <th>age</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WILLIAM SHAKESPEARE</td>\n",
       "      <td>Let the bird of loudest lay\\r\\nOn the sole Ara...</td>\n",
       "      <td>The Phoenix and the Turtle</td>\n",
       "      <td>Renaissance</td>\n",
       "      <td>Mythology &amp; Folklore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DUCHESS OF NEWCASTLE MARGARET CAVENDISH</td>\n",
       "      <td>Sir Charles into my chamber coming in,\\r\\nWhen...</td>\n",
       "      <td>An Epilogue to the Above</td>\n",
       "      <td>Renaissance</td>\n",
       "      <td>Mythology &amp; Folklore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>THOMAS BASTARD</td>\n",
       "      <td>Our vice runs beyond all that old men saw,\\r\\n...</td>\n",
       "      <td>Book 7, Epigram 42</td>\n",
       "      <td>Renaissance</td>\n",
       "      <td>Mythology &amp; Folklore</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    author  \\\n",
       "0                      WILLIAM SHAKESPEARE   \n",
       "1  DUCHESS OF NEWCASTLE MARGARET CAVENDISH   \n",
       "2                           THOMAS BASTARD   \n",
       "\n",
       "                                             content  \\\n",
       "0  Let the bird of loudest lay\\r\\nOn the sole Ara...   \n",
       "1  Sir Charles into my chamber coming in,\\r\\nWhen...   \n",
       "2  Our vice runs beyond all that old men saw,\\r\\n...   \n",
       "\n",
       "                    poem name          age                  type  \n",
       "0  The Phoenix and the Turtle  Renaissance  Mythology & Folklore  \n",
       "1    An Epilogue to the Above  Renaissance  Mythology & Folklore  \n",
       "2          Book 7, Epigram 42  Renaissance  Mythology & Folklore  "
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>poem name</th>\n",
       "      <th>age</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WILLIAM SHAKESPEARE</td>\n",
       "      <td>Let the bird of loudest layOn the sole Arabian...</td>\n",
       "      <td>The Phoenix and the Turtle</td>\n",
       "      <td>Renaissance</td>\n",
       "      <td>Mythology &amp; Folklore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DUCHESS OF NEWCASTLE MARGARET CAVENDISH</td>\n",
       "      <td>Sir Charles into my chamber coming in,When I w...</td>\n",
       "      <td>An Epilogue to the Above</td>\n",
       "      <td>Renaissance</td>\n",
       "      <td>Mythology &amp; Folklore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>THOMAS BASTARD</td>\n",
       "      <td>Our vice runs beyond all that old men saw,And ...</td>\n",
       "      <td>Book 7, Epigram 42</td>\n",
       "      <td>Renaissance</td>\n",
       "      <td>Mythology &amp; Folklore</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    author  \\\n",
       "0                      WILLIAM SHAKESPEARE   \n",
       "1  DUCHESS OF NEWCASTLE MARGARET CAVENDISH   \n",
       "2                           THOMAS BASTARD   \n",
       "\n",
       "                                             content  \\\n",
       "0  Let the bird of loudest layOn the sole Arabian...   \n",
       "1  Sir Charles into my chamber coming in,When I w...   \n",
       "2  Our vice runs beyond all that old men saw,And ...   \n",
       "\n",
       "                    poem name          age                  type  \n",
       "0  The Phoenix and the Turtle  Renaissance  Mythology & Folklore  \n",
       "1    An Epilogue to the Above  Renaissance  Mythology & Folklore  \n",
       "2          Book 7, Epigram 42  Renaissance  Mythology & Folklore  "
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing '\\n', '\\r' errors occurs while loading dataframe. \n",
    "df = df.replace('\\n','', regex=True)\n",
    "df = df.replace('\\r','', regex=True)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['i', 'me', 'my', 'myself', 'we'], 211)"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop = stopwords.words('english')\n",
    "punct = list(string.punctuation)\n",
    "stop_words = stop+punct\n",
    "stop_words[:5], len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Mythology & Folklore', 'Nature', 'Love'], dtype=object)"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array(df)\n",
    "df['type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffling numpy array for better predictions.\n",
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((573,), (573,))"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting x_train and y_train values.\n",
    "x = data[:, 1]\n",
    "y = data[:, 4]\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((487,), (487,), (86,), (86,))"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.15)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating document by appending input and output data.\n",
    "# here we've 3 types of classes i.e Mythology & Folklore, Nature and love.\n",
    "train_documents = []\n",
    "for i in range(len(x_train)):\n",
    "    train_documents.append((x_train[i], y_train[i]))\n",
    "# train_documents[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating documents for test.\n",
    "test_documents = []\n",
    "for i in range(len(x_test)):\n",
    "    test_documents.append((x_test[i], y_test[i]))\n",
    "#test_documents[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have used wordnet Lemmatizer.\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to clean our documents i.e. removing stop_words, addig posTag in documents.\n",
    "def clean_documents(poems):\n",
    "    clean_poems = []\n",
    "    peoms_list = text_to_word_sequence(poems) # text_word_seq split words, filter out punctuation and converts text to lowercase.\n",
    "    #print(peoms_list,end=\" \")\n",
    "    for t in peoms_list:\n",
    "        if t not in stop_words:\n",
    "            postag = pos_tag([t]) # getting posTag of a word. \n",
    "            #print(type(t))\n",
    "            clean_word = lemmatizer.lemmatize(t, pos = get_pos_tag_value(postag[0][1]))\n",
    "            clean_poems.append(clean_word.lower())\n",
    "    return clean_poems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_documents_train = [(clean_documents(poems), genre) for poems, genre in train_documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_documents_test = [(clean_documents(poems), genre) for poems, genre in test_documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(new_documents_test[0][0], new_documents_train[0][1], end=\"\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(new_documents[0][0], new_documents_test[0][1], end = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((487,), (487,), (86,), (86,))"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_input_train = np.array([\" \".join(poem) for poem, genre in new_documents_train])\n",
    "all_output_train = np.array([genre for poem, genre in new_documents_train])\n",
    "all_input_test = np.array([\" \".join(poem) for poem, genre in new_documents_test])\n",
    "all_output_test = np.array([genre for poem, genre in new_documents_test])\n",
    "all_input_train.shape, all_output_train.shape, all_input_test.shape, all_output_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now i have used CountVectorizer to get maximum frequency words and ngrams can also be used for better accuracy.\n",
    "count_vec = CountVectorizer(max_features = 15000, ngram_range = (1, 4))\n",
    "x_train_new = count_vec.fit_transform(all_input_train)\n",
    "y_train_new = all_output_train\n",
    "x_test_new = count_vec.transform(all_input_test)\n",
    "y_test_new = all_output_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((487, 15000), (86, 15000), (487,), (86,))"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_new.shape, x_test_new.shape, y_train_new.shape, y_test_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_encode = LabelEncoder()\n",
    "# y_train_new = label_encode.fit_transform(y_train_new)\n",
    "# y_test_new = label_encode.transform(y_test_new)\n",
    "# y_train_new[:2], y_test_new[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train_new, y_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8891170431211499"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy on training set.\n",
    "rf.score(x_train_new, y_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7209302325581395"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(x_test_new, y_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=750, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC(750, kernel = 'rbf')\n",
    "svc.fit(x_train_new, y_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8891170431211499"
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score on training data.\n",
    "svc.score(x_train_new, y_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6744186046511628"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score on testing data.\n",
    "svc.score(x_test_new, y_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp = svc.predict(x_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(x_train_new, y_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7967145790554415"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.score(x_train_new, y_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6976744186046512"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.score(x_test_new, y_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr = x_train_new\n",
    "y_tr = y_train_new\n",
    "x_te = x_test_new\n",
    "y_te = y_test_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=10, shuffle = True)\n",
    "skf.get_n_splits(x_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=10, random_state=None, shuffle=True)\n"
     ]
    }
   ],
   "source": [
    "print(skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = []\n",
    "for trainindex, testindex in skf.split(x_tr, y_tr):\n",
    "    xtr, xte = x_tr[trainindex], x_tr[testindex]\n",
    "    ytr, yte = y_tr[trainindex], y_tr[testindex]\n",
    "    rfc = SVC(750, kernel = 'rbf')\n",
    "    rfc.fit(xtr, ytr)\n",
    "    output = rfc.score(xte, yte)\n",
    "    score.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.58,\n",
       " 0.52,\n",
       " 0.68,\n",
       " 0.5510204081632653,\n",
       " 0.5306122448979592,\n",
       " 0.7291666666666666,\n",
       " 0.5416666666666666,\n",
       " 0.625,\n",
       " 0.7083333333333334,\n",
       " 0.6595744680851063]"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using GridSearch to find best parameters for SVC.\n",
    "tuned_para = [{'kernel' : ['rbf'], 'gamma': [1e-2, 1e-3, 1e-4], \n",
    "               'C' : [1, 10, 100, 1000, 1500]}, {'kernel' : ['linear'], \n",
    "                'C' : [1, 10, 100, 1000]}]\n",
    "scores= ['precision', 'recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(SVC(), tuned_para, cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'kernel': ['rbf'], 'gamma': [0.01, 0.001, 0.0001], 'C': [1, 10, 100, 1000, 1500]}, {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.0001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfsvc = SVC(C=100, gamma=0.0001, kernel='rbf')\n",
    "clfsvc.fit(x_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8562628336755647"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfsvc.score(x_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6976744186046512"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfsvc.score(x_te, y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      precision    recall  f1-score   support\n",
      "\n",
      "                Love       0.74      0.87      0.80        53\n",
      "Mythology & Folklore       0.00      0.00      0.00         4\n",
      "              Nature       0.67      0.48      0.56        29\n",
      "\n",
      "         avg / total       0.68      0.70      0.68        86\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_te, clfsvc.predict(x_te)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
